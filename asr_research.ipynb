{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef95dcac-de0d-4d29-b54b-5958ce0752ba",
   "metadata": {},
   "source": [
    "## Задача 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cab09c7-9cb3-40ea-8dd0-7a1b42180dbd",
   "metadata": {},
   "source": [
    "Написать программу, которая распознает голосовые фразы:\n",
    "\r\n",
    "1.\t\"привет я разработчик\" и отвечает \"сегодня выходной\".\r\n",
    "2.\t\"Я сегодня не приду домой\" и отвечает \"Ну и катись отсюда\".\r\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdf46f07-c7f3-4097-9363-43cc4c2c8623",
   "metadata": {},
   "source": [
    "### Требования:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4b6acd0-2cc2-4a27-a78a-43dbbaf07aa2",
   "metadata": {},
   "source": [
    "1.\tПровести анализ и сравнение моделей для распознавания текста.\r\n",
    "2.\tВыбрать лучшую модель с учетом скорости распознавания и обосновать свой выбор.\r\n",
    "3.\tДля генерации текста (проговаривания ответа) можно использовать любую модель.\r\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d2444f6-06e0-408b-a326-716bd2455e3d",
   "metadata": {},
   "source": [
    "### Ожидаемые результаты:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "744401b5-c911-4d58-b946-7c2dc1994dd6",
   "metadata": {},
   "source": [
    "1.\tПрограмма должна корректно распознавать указанные голосовые фразы и давать соответствующий ответ.\r\n",
    "2.\tПодробный анализ моделей для распознавания текста, включая сравнение точности и скорости выполнения.\r\n",
    "3.\tОбоснование выбора модели.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bab7f0-5751-4d15-8aa1-afc9b98367cb",
   "metadata": {},
   "source": [
    "## Задача 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f1c8f55-713c-4a13-b3d1-bd74cc499fa8",
   "metadata": {},
   "source": [
    "Используя платформу Huggingface, провести анализ моделей или использовать готовую библиотеку Python для разделения аудиодорожки на отдельные персоны и распознать текст, сказанный каждой персоной на аудио."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc1ec0-0fab-492e-82ca-7a698930bf6a",
   "metadata": {},
   "source": [
    "### Требования:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be4e28d3-49ee-4b88-8b32-f13fd6e98015",
   "metadata": {},
   "source": [
    "1.\tРазделить аудиодорожку на несколько сегментов, каждый из которых соответствует отдельной персоне.\r\n",
    "2.\tИспользовать код из первой задачи для распознавания текста, сказанного каждой персоной.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f58601-fea6-4924-963c-4286190b0d2e",
   "metadata": {},
   "source": [
    "### Ожидаемые результаты:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b2af577-9a97-47c7-9c3d-6492ec7cd9bf",
   "metadata": {},
   "source": [
    "1.\tКод для разделения аудиодорожки на отдельные персоны.\r\n",
    "2.\tПрограмма, которая распознает текст, сказанный каждой персоной на аудио.\r\n",
    "3.\tАнализ и обоснование выбранных методов и моделей.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010161c-b593-47b0-b09d-61e03d1f3fd1",
   "metadata": {},
   "source": [
    "## Решение задачи №1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27616cb-1dd5-42da-8d5d-34fb89590c42",
   "metadata": {},
   "source": [
    "Буду использовать SpeechRecognition — это популярная библиотека для распознавания речи на Python. Она поддерживает несколько движков распознавания, включая Google Web Speech API. Эта библиотека является отличным выбором для нашей первой задачи. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6ef3ae-26ba-468c-afa3-2fe456afa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5acd2045-eb1c-415f-9472-c0c450060931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для распознания речи с помощью микрофона и Google Web Speech API\n",
    "def recognize_speech_from_mic(recognizer, microphone):\n",
    "    with microphone as source:\n",
    "# адаптации к фоновому шуму, чтобы улучшить качество распознавания речи \n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "# записывает аудио с микрофона        \n",
    "        audio = recognizer.listen(source)\n",
    "    response = {\n",
    "        \"success\": True,\n",
    "        \"error\": None,\n",
    "        \"transcription\": None\n",
    "    }\n",
    " # распознавание речи с использованием Google Web Speech API  \n",
    "    try:\n",
    "        response[\"transcription\"] = recognizer.recognize_google(audio, language=\"ru-RU\")\n",
    "    except sr.RequestError:\n",
    "        response[\"success\"] = False\n",
    "        response[\"error\"] = \"API unavailable\"\n",
    "    except sr.UnknownValueError:\n",
    "        response[\"error\"] = \"Unable to recognize speech\"\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ee6f09-1392-42d9-bf7a-683a8a12c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция проверяет, соответствует ли транскрипция заданным условиям и воспроизводит ответ\n",
    "def respond_to_speech(transcription):\n",
    "    if transcription == \"Привет я разработчик\":\n",
    "        response_text = \"Сегодня выходной\"\n",
    "    elif transcription == \"Я сегодня не приду домой\":\n",
    "        response_text = \"Ну и катись отсюда\"\n",
    "    else:\n",
    "        response_text = \"Неизвестная команда\"\n",
    "\n",
    "    print(\"Ответ оператора: {}\".format(response_text))\n",
    "# генерация аудиофайла с помощью Google Text-to-Speech   \n",
    "    tts = gTTS(text=response_text, lang='ru')\n",
    "# сохранение и воспроизведение аудиофайла  \n",
    "    tts.save(\"response.mp3\")\n",
    "    os.system(\"mpg321 response.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5026b6f0-392e-4946-bfe3-634ae177ae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скажите что-нибудь...\n",
      "Разработчик: Привет я разработчик\n",
      "Ответ оператора: Сегодня выходной\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "High Performance MPEG 1.0/2.0/2.5 Audio Player for Layer 1, 2, and 3.\n",
      "Version 0.3.2-1 (2012/03/25). Written and copyrights by Joe Drew,\n",
      "now maintained by Nanakos Chrysostomos and others.\n",
      "Uses code from various people. See 'README' for more!\n",
      "THIS SOFTWARE COMES WITH ABSOLUTELY NO WARRANTY! USE AT YOUR OWN RISK!\n",
      "tcgetattr(): Inappropriate ioctl for device\n",
      "\n",
      "Playing MPEG stream from response.mp3 ...\n",
      "MPEG 2.0 layer III, 64 kbit/s, 24000 Hz mono\n",
      "                                                                            \n",
      "[0:01] Decoding of response.mp3 finished.\n"
     ]
    }
   ],
   "source": [
    "# запускаем программу\n",
    "if __name__ == \"__main__\":\n",
    "    recognizer = sr.Recognizer()\n",
    "    microphone = sr.Microphone()\n",
    "    print(\"Скажите что-нибудь...\")\n",
    "    response = recognize_speech_from_mic(recognizer, microphone)\n",
    "    if response[\"success\"]:\n",
    "        print(\"Разработчик: {}\".format(response[\"transcription\"]))\n",
    "        respond_to_speech(response[\"transcription\"])\n",
    "    else:\n",
    "        print(\"Ошибка: {}\".format(response[\"error\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410279a-b86d-4990-8807-8ae5ad833b91",
   "metadata": {},
   "source": [
    "## Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cbe6ea-91e7-47c8-8d36-432f58287e5e",
   "metadata": {},
   "source": [
    "Задача выполнена, программа распознает речь и отвечает согласно заданным условия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2ffa1-761d-4e5e-a145-9e1c8d0e8b51",
   "metadata": {},
   "source": [
    "## Решение задачи №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2922882c-41a6-4a50-b28a-bb01b7f53cf0",
   "metadata": {},
   "source": [
    "Для задачи выбрал более информативный диалог. Аудио файлы прилагаются.\n",
    "\n",
    "— Алло, привет Катюша.\n",
    "\n",
    " \n",
    "\n",
    "— Приветик!\n",
    "\n",
    " \n",
    "\n",
    "— Я тебе вчера весь вечер звонила, так и не дозвонилась!\n",
    "\n",
    " \n",
    "\n",
    "— Я не слышала, как ты звонила. Я готовила ужин и убиралась в квартире целый вечер.  Как у тебя дела? Чем занимаешься?\n",
    "\n",
    " \n",
    "\n",
    "— Я сейчас иду к врачу у меня зуб болит, а ты что делаешь?\n",
    "\n",
    " \n",
    "\n",
    "— Я еду в турагентство. Мы с Сашей хотим съездить на море отдохнуть.\n",
    "\n",
    " \n",
    "\n",
    "— Вы уже выбрали страну?\n",
    "\n",
    " \n",
    "\n",
    "— Нет ещё, но в прошлом году мы ездили на наш юг – нам очень понравилось! Может и в этом году туда поедем.  А у тебя есть планы на лето?\n",
    "\n",
    " \n",
    "\n",
    "— Да, я думала поехать заграницу. Я каждый год езжу на наш юг, хочется чего-то нового!\n",
    "\n",
    " \n",
    "\n",
    "— Понятно. А что ты делаешь сегодня вечером?\n",
    "\n",
    " \n",
    "\n",
    "—  Я думала в кино сходить. Может вместе сходим?\n",
    "\n",
    " \n",
    "\n",
    "— А у меня есть два билета в театр, на работе раздавали. Пойдёшь со мной?\n",
    "\n",
    " \n",
    "\n",
    "— Ой, с удовольствием! Обожаю театр!\n",
    "\n",
    " \n",
    "\n",
    "— Спектакль начинается в 19:00. Давай встретимся у выхода из метро в 18:30.\n",
    "\n",
    " \n",
    "\n",
    "— Хорошо. До встречи!\n",
    "\n",
    " \n",
    "\n",
    "— Пока!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fe118-059f-426b-8eed-28ece90d5ed3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### План работы"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e68644d9-700f-4a58-b534-79f1be46f4a3",
   "metadata": {},
   "source": [
    "Расссмотрим две популярные модели на платформе Huggingface, а точнее популярные гибриды:\n",
    "- vosk-model-ru-0.42 (модель для распознавания речи на русском языке, использует технологию машинного обучения для анализа аудиозаписи и преобразования её в текст + SbertPuncCase (модель восстановления пунктуации и регистра для русского языка).\n",
    "- whisper/pyannote/speaker-diarization-3.1 (модель  используется для распознавания речи и определения количества говорящих в аудиозаписи.  Модель позволяет автоматически определять количество говорящих и их идентификаторы в аудиозаписи, что может быть полезно при анализе разговоров, интервью или других аудиоматериалов.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aac9478-0724-4144-92b2-1dd22ff31747",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### vosk-model-ru-0.42 + SbertPuncCase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a9212-07ed-4f6a-a116-1ebcd358292b",
   "metadata": {},
   "source": [
    "### кодовое окно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcac9bef-f7ca-4c4c-ae67-397a5c0e3871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/urvanov_aleksandr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 1 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 2 orphan components.\n",
      "LOG (VoskAPI:Collapse():nnet-utils.cc:1488) Added 1 components, removed 2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /Users/urvanov_aleksandr/.cache/vosk/vosk-model-ru-0.42/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from /Users/urvanov_aleksandr/.cache/vosk/vosk-model-ru-0.42/graph/HCLG.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:294) Loading words from /Users/urvanov_aleksandr/.cache/vosk/vosk-model-ru-0.42/graph/words.txt\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo /Users/urvanov_aleksandr/.cache/vosk/vosk-model-ru-0.42/graph/phones/word_boundary.int\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading subtract G.fst model from /Users/urvanov_aleksandr/.cache/vosk/vosk-model-ru-0.42/rescore/G.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:312) Loading CARPA model from /Users/urvanov_aleksandr/.cache/vosk/vosk-model-ru-0.42/rescore/G.carpa\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:318) Loading RNNLM model from /Users/urvanov_aleksandr/.cache/vosk/vosk-model-ru-0.42/rnnlm/final.raw\n",
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import wave\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "from sbert_punc_case_ru import SbertPuncCase\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "SetLogLevel(0)\n",
    "\n",
    "def format_time(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = seconds % 60\n",
    "    time_str = \"{:02d}:{:02d}:{:05.2f}\".format(hours, minutes, seconds)\n",
    "    return time_str\n",
    "\n",
    "def assign_time_to_sentences(sentences, words_timings):\n",
    "    sentence_times = []\n",
    "    timings_index = 0\n",
    "    num_timings = len(words_timings)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_start_time = None\n",
    "        sentence_end_time = None\n",
    "\n",
    "        sanitized_sentence = \"\".join([char for char in sentence if char.isalnum() or char.isspace()]).split()\n",
    "        words_found = 0\n",
    "\n",
    "        while timings_index < num_timings and words_found < len(sanitized_sentence):\n",
    "            word_timing = words_timings[timings_index]\n",
    "            word = word_timing[0]\n",
    "            word_start_time = word_timing[1]\n",
    "            word_end_time = word_timing[2]\n",
    "\n",
    "            sanitized_word = \"\".join([char for char in word if char.isalnum()])\n",
    "\n",
    "            if sanitized_word.lower() == sanitized_sentence[words_found].lower():\n",
    "                if sentence_start_time is None:\n",
    "                    sentence_start_time = word_start_time\n",
    "                sentence_end_time = word_end_time\n",
    "                words_found += 1\n",
    "\n",
    "            timings_index += 1\n",
    "        \n",
    "        if sentence_start_time is not None and sentence_end_time is not None:\n",
    "            sentence_times.append({\n",
    "                \"start\": sentence_start_time,\n",
    "                \"end\": sentence_end_time,\n",
    "                \"sentence\": sentence\n",
    "            })\n",
    "\n",
    "    return sentence_times\n",
    "\n",
    "def run_vosk(input_audio_file, output_text_file):\n",
    "    try:\n",
    "        \"\"\" Открытие WAV файла \"\"\"\n",
    "        wf = wave.open(input_audio_file, \"rb\")\n",
    "    except IOError as err:\n",
    "        return [False, f\"Failed to open WAV file. Error: {err}\"]\n",
    "    \n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "        return [False, \"Audio file must be WAV format mono PCM.\"]\n",
    "    \n",
    "    try:\n",
    "        model = Model(model_name=\"vosk-model-ru-0.42\")\n",
    "        rec = KaldiRecognizer(model, wf.getframerate())\n",
    "        rec.SetWords(True)\n",
    "        rec.SetPartialWords(True)\n",
    "\n",
    "        words_timings = []\n",
    "        text_for_punctuation = \"\"\n",
    "\n",
    "        while True:\n",
    "            data = wf.readframes(4000)\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "            if rec.AcceptWaveform(data):\n",
    "                res = json.loads(rec.Result())\n",
    "                if \"result\" in res:\n",
    "                    for word_info in res[\"result\"]:\n",
    "                        words_timings.append((word_info[\"word\"], word_info[\"start\"], word_info[\"end\"]))\n",
    "                        text_for_punctuation += word_info[\"word\"] + \" \"\n",
    "\n",
    "        model_punc = SbertPuncCase()\n",
    "        text_with_punctuation = model_punc.punctuate(text_for_punctuation)\n",
    "\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        sentences = sent_tokenize(text_with_punctuation, language=\"russian\")\n",
    "\n",
    "        sentence_times = assign_time_to_sentences(sentences, words_timings)\n",
    "\n",
    "        with open(output_text_file, \"w\", encoding='utf-8') as out_file:\n",
    "            for item in sentence_times:\n",
    "                start_time_formatted = format_time(item[\"start\"])\n",
    "                end_time_formatted = format_time(item[\"end\"])\n",
    "                out_file.write(f\"[{start_time_formatted}, {end_time_formatted}] - {item['sentence']}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return [False, f\"Unexpected error: {e}\"]\n",
    "\n",
    "    return [True]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_audio_file = r\"/Users/urvanov_aleksandr/Documents/Yandex/Projects/razgovor_telephone.wav\"\n",
    "    output_text_file = r\"razgovor_telephone_vosk.txt\"\n",
    "    result = run_vosk(input_audio_file, output_text_file)\n",
    "    if result[0]:\n",
    "        print(\"Processing completed successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7247a6f-de83-4fd3-89d4-53429b134e69",
   "metadata": {},
   "source": [
    "### результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fae625-f96b-45bf-8f30-840cb33bbffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:00.48, 00:00:01.65] - Алло, Привет, Катюша.\n",
      "[00:00:01.89, 00:00:02.73] - приветик.\n",
      "[00:00:02.88, 00:00:05.88] - Я тебе вчера весь вечер звонила, так и не дозвонилась.\n",
      "[00:00:06.09, 00:00:08.07] - Я не слышала, как ты звонила.\n",
      "[00:00:08.40, 00:00:12.09] - Я готовила ужин и убиралась в квартире целый вечер.\n",
      "[00:00:12.36, 00:00:13.44] - Как у тебя дела?\n",
      "[00:00:13.71, 00:00:14.94] - Чем занимаешься?\n",
      "[00:00:15.24, 00:00:17.76] - Я сейчас иду к врачу, у меня зуб болит.\n",
      "[00:00:18.09, 00:00:19.08] - А ты что делаешь?\n",
      "[00:00:19.50, 00:00:21.24] - Я еду в турагентство.\n",
      "[00:00:21.54, 00:00:24.45] - Мы с Сашей хотим съездить на море, отдохнуть.\n",
      "[00:00:24.75, 00:00:26.01] - Вы уже выбрали страну?\n",
      "[00:00:26.43, 00:00:27.24] - Нет ещё.\n",
      "[00:00:27.54, 00:00:32.25] - Но в прошлом году мы ездили на наш юг, нам очень понравилось.\n",
      "[00:00:32.49, 00:00:34.62] - Может, и в этом году туда поедем.\n",
      "[00:00:34.80, 00:00:37.32] - А у тебя есть планы на лето, да?\n",
      "[00:00:37.32, 00:00:38.82] - Я думала поехать за границу.\n",
      "[00:00:39.06, 00:00:40.92] - Я каждый год езжу на наш юг.\n",
      "[00:00:41.16, 00:00:42.51] - Хочется чего-то нового.\n",
      "[00:00:42.78, 00:00:43.56] - Понятно.\n",
      "[00:00:43.80, 00:00:45.90] - А что ты делаешь сегодня вечером?\n",
      "[00:00:46.32, 00:00:47.61] - Я думала в кино сходить.\n",
      "[00:00:47.79, 00:00:48.93] - Может, вместе сходим.\n",
      "[00:00:49.23, 00:00:53.04] - А у меня есть два билета в театр. на работе раздавали.\n",
      "[00:00:53.37, 00:00:54.39] - Пойдёшь со мной?\n",
      "[00:00:54.66, 00:00:55.74] - Ой, с удовольствием.\n",
      "[00:00:55.77, 00:01:00.18] - Обожаю театр. Спектакль начинается в девятнадцать ноль ноль.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('razgovor_telephone_vosk.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143752e-2dd8-4f83-9e3c-7b855ac5785e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### whisper/pyannote/speaker-diarization-3.1 для диалога на русском языке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d59f74b-5143-4bdc-8054-b806a516e5e5",
   "metadata": {},
   "source": [
    "### кодовое окно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd56b78-ef8b-4fa0-acf9-3d828214f646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/layer3.c:INT123_do_layer3():1801] error: dequantization failed!\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1801] error: dequantization failed!\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=\"use_auth_token\")\n",
    "\n",
    "\n",
    "def read(k):\n",
    "    y = np.array(k.get_array_of_samples())\n",
    "    return np.float32(y) / 32768\n",
    "\n",
    "\n",
    "def millisec(timeStr):\n",
    "    spl = timeStr.split(\":\")\n",
    "    return (int)((int(spl[0]) * 60 * 60 + int(spl[1]) * 60 + float(spl[2])) * 1000)\n",
    "\n",
    "k = str(pipeline(\n",
    "    \"/Users/urvanov_aleksandr/Documents/Yandex/Projects/razgovor_telephone.mp3\")).split('\\n')\n",
    "\n",
    "del pipeline\n",
    "gc.collect()\n",
    "\n",
    "audio = AudioSegment.from_mp3(\n",
    "    \"/Users/urvanov_aleksandr/Documents/Yandex/Projects/razgovor_telephone.mp3\")\n",
    "audio = audio.set_frame_rate(16000)\n",
    "\n",
    "model = whisper.load_model(\"large-v3\")\n",
    "\n",
    "for l in range(len(k)):\n",
    "\n",
    "    j = k[l].split(\" \")\n",
    "    start = int(millisec(j[1]))\n",
    "    end = int(millisec(j[4][:-1]))\n",
    "\n",
    "    tr = read(audio[start:end])\n",
    "\n",
    "    result = model.transcribe(tr, fp16=False)\n",
    "\n",
    "    f = open(\"/Users/urvanov_aleksandr/Documents/Yandex/Projects/razgovor_telephone_whisper.txt\", \"a\")\n",
    "    f.write(f'\\n[ {j[1]} -- {j[3]} ] {j[6]} : {result[\"text\"]}')\n",
    "    f.close()\n",
    "\n",
    "    del f\n",
    "    del result\n",
    "    del tr\n",
    "    del j\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ece7b3-99e3-4aca-be52-6ef0befb0add",
   "metadata": {},
   "source": [
    "### результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86333951-78fc-4950-ae6d-304407a08f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 00:00:00.520 --  ] SPEAKER_00 :  Алло, привет, Катюша. Приветик. Я тебе вчера весь вечер звонила, так и не дозвонилась. Я не слышала, как ты звонила. Я готовила ужин и убиралась в квартире целый вечер. Как у тебя дела? Чем занимаешься? Я сейчас иду к врачу. У меня зуб болит. А ты что делаешь? Я еду в турагентство. Мы с Сашей хотим съездить на море отдохнуть. Вы уже выбрали страну?\n",
      "[ 00:00:26.389 --  ] SPEAKER_00 :  Нет ещё. Но в прошлом году мы ездили на наш юг. Нам очень понравилось. Может, и в этом году туда поедем. А у тебя есть планы на лето? Да, я думала поехать за границу. Я каждый год езжу на наш юг. Хочется чего-то нового. Понятно. А что ты делаешь сегодня вечером? Я думала в кино сходить. Может, вместе сходим? А у меня есть два билета в театр. На работе раздавали. Пойдёшь со мной? Ой, с удовольствием. Обожаю театр.\n",
      "[ 00:00:57.372 --  ] SPEAKER_00 :  Спектакль начинается в 19.00.\n",
      "[ 00:01:00.443 --  ] SPEAKER_00 :  Давай встретимся у выхода из метро в 18.30.\n",
      "[ 00:01:04.459 --  ] SPEAKER_00 :  Хорошо. До встречи.\n",
      "[ 00:01:06.467 --  ] SPEAKER_00 :  Пока!\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/urvanov_aleksandr/Documents/Yandex/Projects/razgovor_telephone_whisper.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc80aa0-2f99-43c8-bd04-1f5c422fddc1",
   "metadata": {},
   "source": [
    "### whisper/pyannote/speaker-diarization-3.1 для диалога на анлийско языке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e1a79-750a-42fe-821a-32a7d8dccba6",
   "metadata": {},
   "source": [
    "Для эксперимента попробую диалог на английском этой же модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea998644-721b-4ce9-b734-11c69092c8b8",
   "metadata": {},
   "source": [
    "### кодовое окно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "378e8b4e-c704-41b9-abe2-98cc383225ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=\"use_auth_token\")\n",
    "\n",
    "\n",
    "def read(k):\n",
    "    y = np.array(k.get_array_of_samples())\n",
    "    return np.float32(y) / 32768\n",
    "\n",
    "\n",
    "def millisec(timeStr):\n",
    "    spl = timeStr.split(\":\")\n",
    "    return (int)((int(spl[0]) * 60 * 60 + int(spl[1]) * 60 + float(spl[2])) * 1000)\n",
    "\n",
    "k = str(pipeline(\n",
    "    \"/Users/urvanov_aleksandr/Documents/Yandex/Projects/interview_eng.mp3\")).split('\\n')\n",
    "\n",
    "del pipeline\n",
    "gc.collect()\n",
    "\n",
    "audio = AudioSegment.from_mp3(\n",
    "    \"/Users/urvanov_aleksandr/Documents/Yandex/Projects/interview_eng.mp3\")\n",
    "audio = audio.set_frame_rate(16000)\n",
    "\n",
    "model = whisper.load_model(\"large-v3\")\n",
    "\n",
    "for l in range(len(k)):\n",
    "\n",
    "    j = k[l].split(\" \")\n",
    "    start = int(millisec(j[1]))\n",
    "    end = int(millisec(j[4][:-1]))\n",
    "\n",
    "    tr = read(audio[start:end])\n",
    "\n",
    "    result = model.transcribe(tr, fp16=False)\n",
    "\n",
    "    f = open(\"/Users/urvanov_aleksandr/Documents/Yandex/Projects/interview_eng_whisper.txt\", \"a\")\n",
    "    f.write(f'\\n[ {j[1]} -- {j[3]} ] {j[6]} : {result[\"text\"]}')\n",
    "    f.close()\n",
    "\n",
    "    del f\n",
    "    del result\n",
    "    del tr\n",
    "    del j\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464cd2b1-d5c3-4d0a-8dc5-b440841cfe04",
   "metadata": {},
   "source": [
    "### результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "954e8c14-3996-443d-a47c-005cec518bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 00:00:01.380 --  ] SPEAKER_00 : \n",
      "[ 00:00:02.039 --  ] SPEAKER_00 :  framework that we work with in that if there is surplus government land that it is put to the market for disposal. So I suppose there is that little bit of conflict, perceived conflict, with what we do and the policy that exists.\n",
      "[ 00:00:10.189 --  ] SPEAKER_01 :  Yeah.\n",
      "[ 00:00:20.635 --  ] SPEAKER_02 :  So it's probably quite variable, I guess, depending on the politics of the day. You mentioned that there's a framework you're working within there. Would you say you're more guided by that?\n",
      "[ 00:00:28.802 --  ] SPEAKER_02 :  framework or the politics of the day when you're making those decisions.\n",
      "[ 00:00:33.325 --  ] SPEAKER_00 :  It is the framework.\n",
      "[ 00:00:34.995 --  ] SPEAKER_02 :  Yes.\n",
      "[ 00:00:35.012 --  ] SPEAKER_00 :  So the government land transaction guidelines dictate that we are selling government land.\n",
      "[ 00:00:41.492 --  ] SPEAKER_02 :  Okay.\n",
      "[ 00:00:42.134 --  ] SPEAKER_00 :  or surplus government land I should say.\n",
      "[ 00:00:43.973 --  ] SPEAKER_02 :  Yep.\n",
      "[ 00:00:44.007 --  ] SPEAKER_00 :  Thank you.\n",
      "[ 00:00:44.580 --  ] SPEAKER_00 :  So that's what we worked within.\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/urvanov_aleksandr/Documents/Yandex/Projects/interview_eng_whisper.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb90d9-e8ce-47fc-8a74-5376fa94eaef",
   "metadata": {},
   "source": [
    "## Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d749e02-cd2a-474e-9455-3dd30457460d",
   "metadata": {},
   "source": [
    "Первая и вторая модель по диалогу на русском имеют проблемы с разделением спикеров. Вторая модель вывела ошибку в самом аудио файле, что могло стать ключевым фактором проблемы с разделением. Эта же модель на английском аудиофайле показала отличный результат.  Для каждой задачи необходим индивидуальный подход. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb3fc4-d5a0-41f9-9d24-1360da3ea10d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
